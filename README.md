

# Caption Generator

This project implements a deep learning model to generate captions for images. The model is built using a pre-trained VGG16 network for feature extraction and LSTM for sequence generation. The project follows these main steps:

1. **Data Preparation**: Preprocesses image and text data.
2. **Feature Extraction**: Utilizes the VGG16 model to extract image features.
3. **Model Training**: Trains an LSTM-based model to generate captions from image features.
4. **Prediction**: Generates captions for new images.

## Requirements
- TensorFlow, Keras, NumPy, Matplotlib

## How to Run
1. Clone the repository.
2. Install dependencies.
3. Follow the notebook for training and generating captions.
